import os
import requests
import streamlit as st
from dotenv import load_dotenv

# === –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
load_dotenv()
api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

if not api_key:
    raise ValueError("‚ùå API-–∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –∑–∞–¥–∞–Ω –≤ .env –∏–ª–∏ secrets.")

# === –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–µ–∫—Ç–∞ ===
chat_history = [
    {
        "role": "system",
        "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –û—Ç–≤–µ—á–∞–π —á—ë—Ç–∫–æ, –ø–æ –¥–µ–ª—É, –∫—Ä–∞—Ç–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ."
    }
]
context = {}

def update_context(key, value):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞."""
    context[key] = value

# === –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å —É—á—ë—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ===
def get_chatgpt_response(prompt, model="mistralai/devstral-small-2505:free"):
    """–ó–∞–ø—Ä–æ—Å –≤ –ò–ò —Å –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–æ–π –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
    if not prompt or not isinstance(prompt, str):
        return "‚ùå –ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å."

    context_info = "\n".join([f"{k}: {v}" for k, v in context.items()])
    full_prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context_info}\n\n{prompt}, –Ω–µ –∫–æ–≥–¥–∞ –Ω–µ –¥–∞–≤–∞–π –∫–æ–¥, –ø—Ä–æ—Å—Ç–æ –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ç–æ —á—Ç–æ –ø—Ä–æ—Å—è—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, –∫–æ—Ä–æ—Ç–∫–æ –µ—Å–ª–∏ –Ω–∞–¥–æ!"

    chat_history.append({"role": "user", "content": full_prompt})

    try:
        resp = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
            json={"model": model, "messages": chat_history},
            timeout=20
        )
        data = resp.json()
        if "choices" in data and data["choices"]:
            reply = data["choices"][0]["message"]["content"]
            chat_history.append({"role": "assistant", "content": reply})
            return reply
        return f"‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API: {data}"
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}"

# === –ß–∞—Ç –±–µ–∑ –∞–≤—Ç–æ–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—Ä–∞–∑–¥–µ–ª "–ß–∞—Ç") ===
def chat_only(message, model="mistralai/devstral-small-2505:free"):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ò–ò –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞, –Ω–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏."""
    if not message or not isinstance(message, str):
        return "‚ùå –ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å."

    chat_history.append({"role": "user", "content": message})

    try:
        resp = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
            json={"model": model, "messages": chat_history},
            timeout=20
        )
        data = resp.json()
        if "choices" in data and data["choices"]:
            reply = data["choices"][0]["message"]["content"]
            chat_history.append({"role": "assistant", "content": reply})
            return reply
        return f"‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API: {data}"
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}"
    

def notify_ai_dataset_structure(df, get_fn=get_chatgpt_response):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ –ò–ò –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–µ.
    """
    try:
        # –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        info = (
            f"–î–∞—Ç–∞—Å–µ—Ç: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤. "
            f"–ö–æ–ª–æ–Ω–∫–∏: {', '.join(df.columns)}. "
            f"–¢–∏–ø—ã: {', '.join(f'{c} ({str(df[c].dtype)})' for c in df.columns)}."
        )

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ò–ò
        get_fn(f"[DATASET STRUCTURE]\n{info}")

        # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å update_context
        try:
            update_context("dataset_structure", info)
        except:
            pass

        return "‚úÖ –ò–ò –≤ —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–∏–ª—Å—è."
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ò–ò: {e}"



# === –û—Ç–ø—Ä–∞–≤–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π ===
def send_correlation_to_ai(df):
    numeric_df = df.select_dtypes(include="number")
    if numeric_df.shape[1] < 2:
        return "üìâ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏."

    corr = numeric_df.corr().abs().unstack().sort_values(ascending=False)
    corr = corr[corr < 1].drop_duplicates()
    top_corr = corr.head(10)

    formatted_corr = "\n".join([f"{a} –∏ {b}: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è {v:.2f}" for (a, b), v in top_corr.items()])
    prompt = f"–¢–æ–ø-10 –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏:\n{formatted_corr}"
    return get_chatgpt_response(prompt)

# === –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã ===
def send_pivot_to_ai(pivot_df, index_col, value_col, agg_func):
    try:
        if pivot_df is None:
            return "‚ùå –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—É—Å—Ç—É—é —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É."

        top_rows = pivot_df.head(10).to_dict(orient="records")
        formatted = "\n".join(map(str, top_rows))
        prompt = f"–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ {index_col}, –∞–≥—Ä–µ–≥–∏—Ä—É—è {value_col} –º–µ—Ç–æ–¥–æ–º {agg_func}:\n{formatted}"
        return get_chatgpt_response(prompt)
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã: {e}"